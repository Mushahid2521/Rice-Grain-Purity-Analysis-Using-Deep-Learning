{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rice Grain Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mushahid2521/Rice-Grain-Purity-Analysis-Using-Deep-Learning/blob/master/Rice_Grain_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USz6pObPCarv",
        "colab_type": "text"
      },
      "source": [
        "# Rice grain Analysis Using Deep Convolutional Neural Network\n",
        "In this Notebook we will see the implementation of the paper named **Rice Purity Analysis using Deep learning**. Our task was to take a scanned image of rice grains like this and convert it to like this to this.  \n",
        "\n",
        "<img src=\"https://github.com/Mushahid2521/Rice-Grain-Purity-Analysis-Using-Deep-Learning/blob/master/images/Test15.jpg?raw=1\" alt=\"Image\" height=\"600\" width=\"400\" align=\"left\"/> \n",
        "<img src=\"https://github.com/Mushahid2521/Rice-Grain-Purity-Analysis-Using-Deep-Learning/blob/master/images/predicted_img.jpg?raw=1\" alt=\"Image\" height=\"600\" width=\"400\" align=\"right\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVP8cSn_ST-B",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Dataset Preparation\n",
        "First of all we need to detect the Individual Rice grains. We can do this by Canny edge detection algorithm. Then we store these individual grains from the Scanned images for training.\n",
        "Code below this takes the Dataset directory containing Scanned grains with corresponding grain type name as Folder name and create another directory containing trainable individual grain dataset after some processing steps. The steps are: \n",
        "\n",
        "1.   Apply Edge detection to full image\n",
        "2.  Find the Contours of the edges to detect individual grains\n",
        "3.  Create a mask to extract the grains and making the background completely black\n",
        "4.  Crop the grains using  opencv ```boundingRect()``` function.\n",
        "5.  Pad the cropped images to specific size (to retain aspect ratio)\n",
        "6.  Save the padded images to definite directory.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p13LmP8gS9cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import imutils\n",
        "import os\n",
        "import numpy as np\n",
        "import pading_the_grain\n",
        "\n",
        "\n",
        "\n",
        "def prepare():\n",
        "\n",
        "    PATH = 'DATASET'\n",
        "    \n",
        "    NEW_PATH = 'TRAINABLE_DATASET'\n",
        "    os.makedirs(NEW_PATH)\n",
        "\n",
        "\n",
        "    for type in os.listdir(PATH):\n",
        "        TYPE_PATH = os.path.join(PATH,type)\n",
        "\n",
        "        print(\"Processing type {}\".format(type))\n",
        "        \n",
        "        if type in os.listdir(NEW_PATH):\n",
        "          continue \n",
        "\n",
        "        NEW_TYPE_PATH = os.path.join(NEW_PATH,type)\n",
        "        os.makedirs(NEW_TYPE_PATH)\n",
        "\n",
        "        i = 1\n",
        "\n",
        "        for image in os.listdir(TYPE_PATH):\n",
        "            IMAGE_PATH = os.path.join(TYPE_PATH,image)\n",
        "\n",
        "            print(\"Processing Image....{}\".format(image))\n",
        "\n",
        "            img = cv2.imread(IMAGE_PATH)\n",
        "            img_grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            canny_img = cv2.Canny(img_grey, 100, 100)\n",
        "\n",
        "\n",
        "            cnts = cv2.findContours(canny_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cnts = imutils.grab_contours(cnts)\n",
        "\n",
        "            mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\n",
        "            cv2.drawContours(mask, cnts, -1, 0, -1)\n",
        "            img[mask == 255] = 0\n",
        "\n",
        "            for c in cnts:\n",
        "                (x, y, w, h) = cv2.boundingRect(c)\n",
        "                # Take only the right grains, in many cases it might remove the broken grains\n",
        "                if (w*h >1600):\n",
        "                    crop = img[y:y + h, x:x + w]\n",
        "                    try:\n",
        "                        crop = pading_the_grain.pad_image(crop, 128, 0)\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                    # remove the images with edges only by counting the non zero pixel values\n",
        "                    if ((49152 - len(crop[crop == 0])) < 2000):\n",
        "                        continue\n",
        "\n",
        "                    image_name = \"{}_{}.png\".format(type,i)\n",
        "                    image_url = os.path.join(NEW_TYPE_PATH,image_name)\n",
        "\n",
        "                    cv2.imwrite(image_url, crop)\n",
        "\n",
        "                    i += 1\n",
        "\n",
        "                   \n",
        "\n",
        "        print(f'Got type {type}', len(os.listdir(NEW_TYPE_PATH)))\n",
        "\n",
        "\n",
        "prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWl5zQpLVlxp",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Data Augmentation\n",
        "The dataset contains different number of scanned images for different grain types. So we increase the amount of data and balance the data by rotating a single grains to different orientations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEaTKtVJW4C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path containing individual grain dataset\n",
        "PATH = 'TRAINABLE_DATASET'\n",
        "\n",
        "# Directory to save the new dataset after augmentation \n",
        "NEW_DATA_PATH = 'ENLARGED_TRAINABLE_DATASET'\n",
        "os.makedirs(NEW_DATA_PATH)\n",
        "\n",
        "# Total number of grains we want to make for each grain type\n",
        "TOTAL_GRAINS = 20000\n",
        "\n",
        "for grain_type in os.listdir(PATH):\n",
        "  p = os.path.join(PATH, grain_type)\n",
        "  \n",
        "  print(f'Working with {grain_type}')\n",
        "  grains = os.listdir(p)\n",
        "  length = len(grains)\n",
        "  \n",
        "  if length>TOTAL_GRAINS:\n",
        "    continue\n",
        "  \n",
        "  more_needed = TOTAL_GRAINS-length\n",
        "  \n",
        "  ratio = int(length/more_needed)\n",
        "  \n",
        "  NEW_TYPE_PATH = os.path.join(NEW_DATA_PATH,grain_type)\n",
        "  os.makedirs(NEW_TYPE_PATH)\n",
        "  \n",
        "      \n",
        "  idx = 0\n",
        "  \n",
        "  for i in range(1,ratio+1):\n",
        "    for gr in grains:\n",
        "      gp = os.path.join(p, gr)\n",
        "      img = cv2.imread(gp)\n",
        "      (h,w) = img.shape[:2]\n",
        "      centre = (w//2, h//2)\n",
        "      \n",
        "      img_name = \"{}_{}.png\".format(grain_type, idx)\n",
        "      img_url = os.path.join(NEW_TYPE_PATH, img_name)\n",
        "      idx+=1\n",
        "      \n",
        "      cv2.imwrite(img_url, img)\n",
        "      \n",
        "      M = cv2.getRotationMatrix2D(centre, 40*i, 1.0)\n",
        "      rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "      \n",
        "      img_name = \"{}_{}.png\".format(grain_type, idx)\n",
        "      img_url = os.path.join(NEW_TYPE_PATH, img_name)\n",
        "      idx+=1\n",
        "      \n",
        "      cv2.imwrite(img_url, rotated)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK2w1a3FYKga",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Prepare the data to feed to the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If7PFnPNanZu",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the type of the grain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIO1ynX7avZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = 'ENLARGED_TRAINABLE_DATASET'\n",
        "label_encoder = {}\n",
        "label_decoder = {}\n",
        "i = 0\n",
        "for grain_type in os.listdir(PATH):\n",
        "  \n",
        "\n",
        "  \n",
        "  label_encoder[str(grain_type)] = i\n",
        "  label_decoder[i] = grain_type\n",
        "  i+=1\n",
        "  \n",
        "print(label_encoder)\n",
        "print(label_decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X330U9RZa4yG",
        "colab_type": "text"
      },
      "source": [
        "### Spliting the training and validation data.\n",
        "We save the paths of the images to pass these to Custom Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjEH6-5bbFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Partition to store all the image path location partiton{'train':[], 'validation':[]}\n",
        "partition = {}\n",
        "partition['train'] = []\n",
        "partition['validation'] = []\n",
        "\n",
        "# Label dict to store the path as key and label index as value\n",
        "label = {}\n",
        "\n",
        "\n",
        "for grain_type in os.listdir(PATH):\n",
        "  #print(\"Collecting type {} has {} items\".format(grain_type, len(os.listdir(PATH+'/'+grain_type))  ))\n",
        "\n",
        "\n",
        "    \n",
        "  type_path = os.path.join(PATH,grain_type)\n",
        "  \n",
        "  type_list = os.listdir(type_path)\n",
        "  \n",
        "  # We shuffle the image lists\n",
        "  np.random.seed(10)\n",
        "  \n",
        "  fixed_type_list = np.random.choice(type_list, size=len(type_list), replace=False)\n",
        "  \n",
        "  train_list = fixed_type_list[3000:]\n",
        "  validation_list = fixed_type_list[:3000]\n",
        "  \n",
        "  for item in train_list:\n",
        "    item_path = os.path.join(type_path, item)\n",
        "    partition['train'].append(item_path)\n",
        "    label[item_path] = label_encoder[grain_type] \n",
        "    \n",
        "  for item in validation_list:\n",
        "    item_path = os.path.join(type_path, item)\n",
        "    partition['validation'].append(item_path)\n",
        "    label[item_path] = label_encoder[grain_type]\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFF3RxiMbwEf",
        "colab_type": "text"
      },
      "source": [
        "### Defining the Custom Keras Data Generator\n",
        "As the size of the Dataset is large. So it is better to use Data Generator to avoid memory issue.\n",
        "This [post](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) helped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh3x7oy-cHvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import imutils\n",
        "\n",
        "no_classes = 8\n",
        " \n",
        "########## Custom Data Generator Class #################\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=64, dim=(128,128), n_channels=3,\n",
        "                 n_classes=no_classes, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find .list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "         \n",
        "      \n",
        "\n",
        "    def __data_generation(self,list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            try:\n",
        "              _ = (cv2.imread(ID).shape!=(128,128,3))\n",
        "            except:\n",
        "              continue\n",
        "            try:\n",
        "              X[i,] = cv2.imread(ID)*(1.0/255.0)\n",
        "              #X_[i,] = generate_data(ID)\n",
        "            except:\n",
        "              continue\n",
        "                \n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMIln7JXdUGl",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Custom Data Generator Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYboX3wZdhDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "training_generator = DataGenerator(partition['train'], label)\n",
        "validation_generator = DataGenerator(partition['validation'], label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Ygvwqqdlsw",
        "colab_type": "text"
      },
      "source": [
        "## Step 4:  Defining our Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iokdA4KxdwSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### Conv Model #############\n",
        "\n",
        "from keras.layers import *\n",
        "\n",
        "model=Sequential()\n",
        "input_shape=(128,128,3)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (5, 5),padding='same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(no_classes, activation = 'softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BL6lwRJek-Q",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YqJceakenx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
        "                             verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "\n",
        "callback_list = [checkpoint, earlyStopping] #\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.fit_generator(generator=training_generator,\n",
        "                      epochs = 10,\n",
        "                      validation_data=validation_generator,\n",
        "                      use_multiprocessing=True,workers=200,\n",
        "                      callbacks=callback_list\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEzEs0DLextE",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AdQZIGde_uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred(image_path):\n",
        "  \n",
        "  k = np.expand_dims(cv2.imread(image_path)*(1.0/255.0), axis=0)\n",
        "  p = model.predict(k)\n",
        "  p = np.argmax(p)\n",
        "  \n",
        "  return label_decoder[p]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX06eZurfoPP",
        "colab_type": "text"
      },
      "source": [
        "# Approach with Morphological Features\n",
        "We also tested the result with Morphological Feature and different Machine Leanring Classifier. For this we have collected  Six morphological features. Using the following opencv functions we accomplish this. \n",
        "\n",
        "<img src=\"https://github.com/Mushahid2521/Rice-Grain-Purity-Analysis-Using-Deep-Learning/blob/master/images/ellipse.jpg?raw=1\" alt=\"Drawing;\"/>\n",
        "<img src=\"https://github.com/Mushahid2521/Rice-Grain-Purity-Analysis-Using-Deep-Learning/blob/master/images/rectangle.jpg?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "\n",
        "```fitEllipse()``` gives major axis length (majLen)  and minor axis length (minLen)\n",
        "\n",
        "```minAreaRect()```  gives length (l) and width (w)\n",
        "\n",
        "```cv2.contourArea``` gives area (A)\n",
        "\n",
        "```cv2.arcLength``` gives perimmeter (P)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        " **Six Features:**\n",
        "1.   Area by Perimeter Ratio:   ($\\frac{A}{P}$)\n",
        "2.   Ratio to the Area to the total of area and perimeter:  $\\frac{A}{(A+P)}$\n",
        "3.   Aspect Ratio: ($\\frac{majLen}{minlen}$)\n",
        "4.   Retangularity: $\\frac{A}{(l*w)}$ \n",
        "5.   Equivalent Diameter: $\\sqrt{\\frac{4A}{\\pi}}$\n",
        "6.   Shape factor 3: $\\frac{A}{l*w}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJYi0pH0zq6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTe91IdgmFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import imutils\n",
        "import math\n",
        "\n",
        "no_classes = 8\n",
        "\n",
        "def generate_data(ID):\n",
        "\n",
        "    img = cv2.imread(ID)\n",
        "    img_grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    canny_img = cv2.Canny(img_grey, 100, 100)\n",
        "      \n",
        "    cnts = cv2.findContours(canny_img.copy(),  cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "      \n",
        "    for c in cnts:\n",
        "      rect = cv2.minAreaRect(c)\n",
        "      ((_, _), (p,q), _) = rect\n",
        "      if(p>=q):\n",
        "          length = p\n",
        "          width = q\n",
        "      else:\n",
        "          length = q\n",
        "          width = p\n",
        "\n",
        "      area = cv2.contourArea(cnts[0])\n",
        "      perimeter = cv2.arcLength(cnts[0], closed=True)\n",
        "      \n",
        "      try:\n",
        "        (_,_), (majax, minax), _ = cv2.fitEllipse(cnts[0])\n",
        "        if(ax1>=ax2):\n",
        "          majax = ax1\n",
        "          minax = ax2\n",
        "        else:\n",
        "          majax = ax2\n",
        "          minax = ax1\n",
        "        return [area/perimeter, area/(area+perimeter), maxax/minax, area/(length*width), math.sqrt(4*area/math.pi), area/(majax*minax)]\n",
        "      \n",
        "      except:\n",
        "        # Sometimes the Fit Ellipse function throws error. So we handle it by try catch block\n",
        "        return [area/perimeter, area/(area+perimeter), length/width, area/(length*width), math.sqrt(4*area/math.pi), area/(length*width)]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ynZKdG-Jn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "PATH = 'ENLARGED_TRAINABLE_DATASET'\n",
        "\n",
        "for grain_type in [os.listdir(PATH)[7]]:\n",
        "  \n",
        "  print(f\"Collecting type {grain_type}\")\n",
        "    \n",
        "  type_path = os.path.join(PATH,grain_type)\n",
        "  \n",
        "  type_list = os.listdir(type_path)\n",
        " \n",
        "  np.random.seed(10)\n",
        "  fixed_type_list = np.random.choice(type_list, size=len(type_list), replace=False)\n",
        "\n",
        "  i = 0 \n",
        "  for item in fixed_type_list:\n",
        "    \n",
        "    item_path = os.path.join(type_path, item)\n",
        "    try:\n",
        "      dat = generate_data(item_path)\n",
        "      i+=1\n",
        "    except:\n",
        "      continue\n",
        "      \n",
        "    if(i%1000==0):\n",
        "      print(i) \n",
        "    \n",
        "    # We keep 3000 for test and rest for training \n",
        "    if(i<=3000):\n",
        "      x_test.append(dat)\n",
        "      y_test.append(label_encoder[grain_type])\n",
        "    #print(\"Done with Validation\")\n",
        "    \n",
        "    else:\n",
        "      x_train.append(dat)\n",
        "      y_train.append(label_encoder[grain_type])\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA05JSDp_YFb",
        "colab_type": "text"
      },
      "source": [
        "### KNN Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v_3EvvN_nnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training a KNN classifier \n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 3).fit(x_train, y_train) \n",
        "  \n",
        "# accuracy on X_test \n",
        "accuracy = knn.score(x_test, y_test) \n",
        "print(accuracy) \n",
        "  \n",
        "# creating a confusion matrix \n",
        "knn_predictions = knn.predict(x_test)  \n",
        "cm = confusion_matrix(y_test, knn_predictions) \n",
        "target_names = label_encoder.keys()\n",
        "print(classification_report(y_test, knn_predictions, target_names=target_names))\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalQJS7l_vJI",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMBx81C_28F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training a DescisionTreeClassifier \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "dtree_model = DecisionTreeClassifier(max_depth=10).fit(x_train, y_train) \n",
        "dtree_predictions = dtree_model.predict(x_test) \n",
        "\n",
        "# accuracy on X_test\n",
        "acc = dtree_model.score(x_test, y_test)\n",
        "print(f\"Accuracy: {acc}\")\n",
        "\n",
        "\n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test,dtree_predictions))\n",
        "print('Classification Report')\n",
        "target_names = label_encoder.keys()\n",
        "print(classification_report(y_test, dtree_predictions, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoJqKtYAV5u",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pspnv9n1AYS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(140, input_shape=(6,), activation='relu'))\n",
        "model.add(Dense(140, activation='relu'))\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "y_tr = to_categorical(y_train)\n",
        "model.fit(x_train, y_tr, epochs=6, batch_size=64, validation_data=(x_test,to_categorical(y_test)))\n",
        "\n",
        "\n",
        "preds = model.predict_classes(x_test)\n",
        "cm = confusion_matrix(y_test, preds) \n",
        "\n",
        "target_names = label_encoder.keys()\n",
        "print(classification_report(y_test, preds, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
